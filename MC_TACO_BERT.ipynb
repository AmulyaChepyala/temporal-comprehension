{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MC TACO - BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2YsQeF1ZaDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0520f258-69b7-4ae8-dda9-855e3045161a"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 99 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30536 sha256=2371dae88713785f108281592a6ab475d2de1f07ab40a43c630fab49a40d95e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19471 sha256=31d5a0d5afbb451e991ca70fbccc33cd356bf30d00bc4adb569df918e94de0fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7910 sha256=e7879021d5272eae10ef3a38a93e09e4c600419345184c7a729cca62a494b68a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 16.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH4P4SgOZmVl"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbb_0XrAZ06c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwMMWRHKZrHt"
      },
      "source": [
        "df = pd.read_csv('/content/test_9442.tsv', delimiter='\\t', header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4xLopEysSJE",
        "outputId": "a9f86873-091e-4a17-9b06-387dcc7836e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTzkKhJ5Zyfb"
      },
      "source": [
        "def data_preprocessing(df):\n",
        "  df.columns=['Statement', 'Question', 'Answer', 'Label', 'Category']\n",
        "  df.dropna(inplace=True)\n",
        "  enc = LabelEncoder()\n",
        "  df['Label'] = enc.fit_transform(df['Label'])\n",
        "  enc2 = LabelEncoder()\n",
        "  df['Category'] = enc2.fit_transform(df['Category'])\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SneHexzFk0Z"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KlFbP4Z_M0"
      },
      "source": [
        "\n",
        "df = data_preprocessing(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpwXtV7CMd5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "017a84c9-cf24-4b1e-ab26-a703ea07ead0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Label</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "      <td>How long was his mother ill?</td>\n",
              "      <td>she was ill for 30 seconds</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "      <td>How long was his mother ill?</td>\n",
              "      <td>six centuries</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "      <td>How long was his mother ill?</td>\n",
              "      <td>she was ill for 90 years</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "      <td>How long was his mother ill?</td>\n",
              "      <td>6 months</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "      <td>How long was his mother ill?</td>\n",
              "      <td>six minutes</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Statement  ... Category\n",
              "0  Durer's father died in 1502, and his mother di...  ...        0\n",
              "1  Durer's father died in 1502, and his mother di...  ...        0\n",
              "2  Durer's father died in 1502, and his mother di...  ...        0\n",
              "3  Durer's father died in 1502, and his mother di...  ...        0\n",
              "4  Durer's father died in 1502, and his mother di...  ...        0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drb8is34TxRh"
      },
      "source": [
        "df['Text'] = df['Statement']+df['Question']+df['Answer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H95XjW8aT4Iz"
      },
      "source": [
        "df = df.drop(['Statement','Question','Answer','Category'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cK_IOEoWUCgM",
        "outputId": "b4ddd55a-a5f7-41ca-c4fb-c4aae4a95f36"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Durer's father died in 1502, and his mother di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               Text\n",
              "0      0  Durer's father died in 1502, and his mother di...\n",
              "1      0  Durer's father died in 1502, and his mother di...\n",
              "2      0  Durer's father died in 1502, and his mother di...\n",
              "3      1  Durer's father died in 1502, and his mother di...\n",
              "4      0  Durer's father died in 1502, and his mother di..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2n_ppgYZ_eH"
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJZNnLAyaCOy"
      },
      "source": [
        "def tokenize(text):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKs8nCCCaTDZ"
      },
      "source": [
        "tokenize= [tokenize(text) for text in df['Text'] ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LmKg5SFa7fR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2673ebf9-6af6-4d40-fa3b-a757959ff096"
      },
      "source": [
        "len(tokenize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9442"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKPN2qJ8XG4d"
      },
      "source": [
        "y = df['Label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cVXePEdnoWw"
      },
      "source": [
        "tokenize = [(text, y[i]) for i, text in enumerate(tokenize)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckSOgBAFglwb"
      },
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: tokenize, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpN3hPE-tOYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952c2bc3-8563-4fca-fe7f-c901f9cb3ba5"
      },
      "source": [
        "processed_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYPRz_j7etrk"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ZqUxP-DztU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec1ca20-ffe6-4727-9e74-718c228212e8"
      },
      "source": [
        "next(iter(batched_dataset))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 37), dtype=int32, numpy=\n",
              " array([[ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 1, 1, 0, 0, 0, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9PidrMigUYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ea7c73-e89d-410c-944d-e66c782a21a3"
      },
      "source": [
        "next(iter(batched_dataset))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 37), dtype=int32, numpy=\n",
              " array([[ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0],\n",
              "        [ 4241, 14544,  1005, ...,     0,     0,     0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 1, 1, 0, 0, 0, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186rFBrWgvss"
      },
      "source": [
        "TOTAL_BATCHES = math.ceil(len(tokenize) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-rrnA40hbp5"
      },
      "source": [
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdW9l083jwW5"
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c68k0gg4j0Rx"
      },
      "source": [
        "text_model = TEXT_MODEL ( vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DWUbAhBb__l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBVk7jRyj3c8"
      },
      "source": [
        "text_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[tf.metrics.Precision(), tf.metrics.Recall()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgcf9cPnj7fv",
        "outputId": "b03534c7-7719-4872-820a-3fbe75a5a7b7"
      },
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "267/267 [==============================] - 31s 113ms/step - loss: 0.3090 - precision: 0.8205 - recall: 0.7694\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 30s 113ms/step - loss: 0.2711 - precision: 0.8311 - recall: 0.8026\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 30s 112ms/step - loss: 0.2738 - precision: 0.8261 - recall: 0.8064\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 30s 112ms/step - loss: 0.2389 - precision: 0.8586 - recall: 0.8230\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 30s 112ms/step - loss: 0.2000 - precision: 0.8763 - recall: 0.8448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07d4d59350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxWz7hePYbb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12edcbcf-dff1-4c2f-d71e-af5f19126a82"
      },
      "source": [
        "results = text_model.evaluate(test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 [==============================] - 1s 24ms/step - loss: 0.7140 - precision: 0.5388 - recall: 0.7738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_mhzNCAq05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890fc5f4-a835-4b28-bf0b-8ecf1f0e2d25"
      },
      "source": [
        "print(\"F1 Score : \", 2*((results[1]*results[2])/(results[1]+results[2])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score :  0.635262435997939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBXN3S9FnVxp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}